##### 基本概念
- 应用：互联网搜索、自动汽车驾驶、画作鉴别、古文献修复、……
  源于人工智能，达特茅斯会议标志着人工智能这一学科的诞生
	推理期（自动定理证明系统）——知识期（专家系统）——学习期（机器学习是作为突破知识工程瓶颈之利器而出现的）
	收集、传输、存储大数据是为了利用大数据，没有机器学习技术分析大数据，利用无从谈起
	
- 监督学习：分类和回归；从有标记的训练数据中推导出预测函数，即每个训练实例都包括输入和期望的输出。
- 无监督学习：聚类；从无标记的训练数据中推断结论
- 强化学习：软件代理在一个环境中一边采取行动一边最大化某种累积的回报
	
- 泛化能力：学得的模型适用于新样本的能力
- 假设空间 假设空间的大小  假设的表示一旦确定，假设空间及其规模大小就确定了
- 版本空间：存在一个与训练集一致的假设集合
- 归纳偏好：机器学习算法在学习过程中对某种类型假设的偏好，任何一个有效的机器学习算法必有其归纳偏好，否则将被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。学习算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。
- 对应了学习算法本身所做的关于“什么样的模型更好”的假设
- 奥卡姆剃刀原则：若有多个假设与观察一致，则选择最简单的那个。
- “没有免费的午餐”定理（NFL定理）前提：所有“问题”出现的机会相同、或所有问题同等重要
	重要的寓意：脱离具体问题，空泛地谈论“什么学习算法更好”毫无意义，若考虑所有的潜在问题，则所有的学习算法都一样好。
---

##### ❗模型评估与选择
1. 错误率 $$E=\frac{a}{m}$$
2. 精度$$1-\frac{a}{m}$$
3. 误差：经验误差/训练误差-- 泛化误差（希望得到泛化误差小的学习器，但实际能做的是努力使经验误差最小化）
	经验误差不是越小越好，会出现过拟合
4. 过拟合$\rightleftarrows$欠拟合
##### 评估方法：获得测试结果
- 留出法：直接将数据集划分为两个互斥的集合，其中一个集合作为训练集，另一个作为测试集，在训练集上训练出模型后，用测试集来评估其测试误差，作为对泛化误差的估计
	保持数据分布的一致性，分层采样
	单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。
	测试集不能太大、不能太小（1/5~1/3）
- 交叉验证法：先将数据集划分成k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，即从D中通过分层采样得到，然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。
	交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，将交叉验证法称为"k折交叉验证"。
	将数据集划分为k个子集同样存在多种划分方式。随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值。
	若令k=m，则得到 **留一法（LOO）**，留一法的结果往往被认为比较准确，但估计结果也未必永远比其他评估方法准确。当数据集比较大时，训练m个模型的计算开销可能是难以忍受的。
- 自助法：基于自助采样法，对数据集进行采样得到D'，每次随机从D中挑选一个样本将其拷贝到D'中，然后再将样本放回到初始数据集D中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行**m次**后，我们就得到了包含m个样本的数据集D'。D中有一部分样本会在D'中多次出现，而另一部分样本不出现。
	实际评估的模型与期望评估的模型都使用m个训练样本，仍有数据总量约1/3的、没在训练集中出现的样本用于测试。（包外估计）
	**在数据集较小、难以有效划分训练/测试集时很有用；能够从初始数据集中产生多个不同的训练集，对集成学习等方法有很大好处。**
	训练集与原样本集同规模
	数据分布有所改变


	调参与最终模型
	算法的参数一般由人工设定，称为超参数
	模型的参数，一般由学习确定
	调参过程相似，先产生若干模型，然后基于某种评估方法进行选择
	参数调的好不好往往对最终性能有关键影响
	算法参数选定之后，要用“训练集+验证集”重新训练最终模型
##### ❗性能度量：如何评估性能优劣
- **回归**
1. 均方误差（回归任务)
$$\begin{aligned} E(f; D) &= \frac{1}{m} \sum_{i=1}^{m} (f(x_i) - y_i) \\ E(f; D) &= \int_{x \sim D} (f(x) - y)^2 p(x) \, dx \end{aligned} $$
- **分类**  
1. 错误率（预测错误的样本数占样本总数的比例）与精度（预测正确的样本数占样本总数的比例）
2. 二分类：真正例（TP）、假正例（FP）、真反例（TN）、假反例（FN）
	TP：真实情况为正例、预测结果为正例
	FP：真实情况为反例、预测结果为正例
	TN：真实情况为正例、预测结果为反例
	FN：真实情况为反例、预测结果为反例
	1. ❗查准率$$P=\frac{TP}{TP+FP}$$
	2. ❗查全率$$R=\frac{TP}{TP+FN}$$
		查准率与查全率相矛盾
		按照测试结果预测为正例的可能性大小对样例进行排序，并逐个把样本作为正例进行预测
		P-R曲线（查准率为纵轴、查全率为横轴）
		若一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，如果两个学习器的P-R曲线发生了交叉，则难以一般性断言两者孰优孰劣
		平衡点（BEP），在查全率等于查准率时的取值，平衡点越大，可认为学习器更优
	3. ❗F1度量
		$$F_1=\frac{2\times P \times R}{p+R}=\frac{2TP}{样例总数+TP-TN}$$
		有时对查准率和查全率的重视程度有所不同，推出F1度量的一般形式：$$F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}$$
		当β>0时，度量了查全率对查准率的相对重要性，当β=1时，退化为F1度量，当β<1时，查准率有更大影响，β>1时，查全率有更大影响。
	4. 多个二分类
		在n个二分类混淆矩阵上综合考察查准率和查全率
		1. 在各混淆矩阵上分别计算出查准率和查全率，再计算平均值，得到宏查准率（macro-P）、宏查全率（macro-R），以及相应的宏F1（macro-F1）
			$$macro-F_1=\frac{2\times macro-P\times macro-R}{macro-P + macro-R}$$
		2. 先将各混淆矩阵的对应元素进行平均，得到$\overline{TP}$、$\overline{FP}$、$\overline{TN}$、$\overline{FN}$，再基于这些平均值计算出微查准率（micro-P）、微查全率（micro-R），以及相应的微F1（micro-F1）
3. ❗ROC曲线：将测试数据集按照预测概率从大到小排序，每次取每个样本的预测概率作为阈值，计算此时的TPR和FPR，并记录下来，分别以它们作为横纵坐标作图，就得到了ROC曲线
	纵轴是真正例率$$TPR=\frac{TP}{TP+FN}$$
	横轴是假正例率$$FPR=\frac{FP}{TN+FP}$$
	对角线对应于随机猜测模型，点（0，1）对应于将所有正例排在所有反例之前的理想模型
	现实中无法绘制出光滑的ROC曲线，只能绘制出近似ROC曲线
	若一个学习器的ROC曲线被另一个学习器的ROC曲线完全包住，则可断言后者的性能优于前者，如果两个学习器的ROC曲线发生了交叉，则难以一般性断言两者孰优孰劣
	较为合理的判据是比较ROC曲线下的面积，即==AUC==
	**AUC的物理含义：随机给定一个正样本A和一个负样本B，分类器对A预测输出为正样本的概率比分类器对B预测输出为正样本的概率大的可能性**
	指示函数$$\mathbb{I}_{x>0} = \begin{cases}1, & \text{if } x > 0\\
		0, & \text{otherwise}\end{cases}$$
	形式化地看，AUC考虑的是样本预测的排序质量，与排序误差有紧密联系。给$m^+$个正例和$m^-$个反例，令$D^+$和$D^-$表示正、反例集合，排序损失：$$l_{rank}=\frac{1}{m^+m^-}\sum_{x^+\in D^+}\sum_{x^-\in D^-}(\mathbb{I}(f(x^+)<f(x^-))+\frac{1}{2}\mathbb{I}(f(x^+)=f(x^-)))$$
	考虑每一对正、反例，若正例的预测值小于反例，记一个罚分，若相等，则记0.5个罚分；$l_{rank}$对应的是ROC曲线之上的面积：若一个正例在ROC曲线上对应标记点的坐标为（x,y），则x恰是排序在其之前的反例所占的比例，即假正例率$$AUC=1-l_{rank}$$
4. 非均等代价，代价敏感错误率：分错的样本数乘以对应的代价求和求平均

##### 比较检验：比较实质差别
在某种度量下取得评估结果后，不能直接比较以评判优劣：
	测试性能不等于泛化性能
	测试性能随着测试集的变化而变化
	很多机器学习算法本身有一定的随机性
显著性检验
- **两学习器比较**
交叉验证t检验(基于成对t检验)
	根据测试错误率推出泛化错误率的分布
	泛化错误率为$\epsilon$的学习器在一个样本上犯错的概率是$\epsilon$；测试错误率为$\hat\epsilon$意味着在m个测试样本中有$m\times\hat\epsilon$个样本被误分类
	k折交叉验证
	$5\times2$交叉验证
McNemar检验
	基于列联表，卡方检验
- **多学习器比较**
Friedman+Nemenyi
Friedman检验，基于序值，F检验，判断多个分类器是否都相同
	Friedman检验图：若两个算法有交叠，说明没有显著差别
	否则有显著差别
Nemenyi后续检验，基于序值，进一步判断两两差别

误差-方差分析
回归任务：
泛化误差
<img src="Pasted image 20250630131555.png" alt="描述" width=500 height=400>
偏差-方差窘境：训练不足时，学习器拟合能力不强，偏差占主导，随着训练程度加深，学习器拟合能力逐渐增强，方差逐渐主导，训练充足后，学习器的拟合能力很强，方差占主导

---
#### 线性模型
试图学得一个通过属性的线性组合来进行预测的函数。简单、基本、可理解性好
##### 线性回归
离散属性的处理：若属性值之间存在“序”关系，可通过连续化将其转化为连续值；若属性之间不存在序关系，假定有k个属性值，则通常转化为k维向量
基于均方误差最小化来实现模型求解的方法称为“**最小二乘法**”。
<img src="Pasted image 20250624160339.png", width =400>
闭式解：
<img src="Pasted image 20250624160229.png" width=300>

<img src="Pasted image 20250624160237.png" width=300>

##### 多元线性回归
最小二乘法求解
<img src="Pasted image 20250624160312.png" width=400>
<img src="Pasted image 20250624160439.png" width=250>
令上式为零，分为$X^TX$满秩和不满秩（可解出多个$w$，需引入正则化或求助于归纳偏好）的情况

##### 广义线性模型
联系函数g(·)，单调可微
$y=g^{-1}(w^Tx+b)$
##### 对数几率回归：分类学习算法
实值输出$z=w^Tx+b$
期望输出$y\in{\{0,1\}}$
联系函数：单位阶跃函数$$ y = \begin{cases} 0, & z < 0 \\ 0.5, & z = 0 \\ 1, & z > 0 \end{cases} $$
单位阶跃函数不连续，使用对数几率函数/sigmoid函数替代$y=\frac{1}{1+e^{-z}}$
$\frac{y}{1-y}$称为几率（odds），反映了x作为正例的相对可能性
$ln\frac{y}{1-y}$称为对数几率
- 无需事先假设数据分布
- 可得到“类别”的近似概率预测
- 可以直接应用现有数值优化算法求解最优解
##### 线性判别分析（LDA）
将样例投影到一条直线（低维空间），因此也被视为一种“监督降维”技术
同类样例的投影点尽可能接近；异类样例的投影点尽可能远离
Fisher：两类分类、投影
两类样本的中心在直线上的投影：$w^T\mu_0$      $w^T\mu_1$
推广到多类：LDA
$S_t = \Sigma_{i=1}^n(X_i-m)(X_i-m)^T$
$S_w = \Sigma_{i=1}^c(\Sigma_{x\in w_k}(x-m_k)(x-m_k)^T)$
$S_b = \Sigma_{i=1}^cn_i(m_i-m)(m_i-m)^T$
$max_w{tr(W^TS_bW)\over tr(W^TSwW)}$
当$S_w$可逆时，$W^*$为$S_w^{-1}S_b$的前$c-1$特征值对应的特征向量组成的矩阵

##### 多分类学习
拆解法：将一个多分类任务拆分为若干个二分类任务求解
OvO：训练$N(N-1)\over{2}$个分类器，存储开销和测试时间大，训练只用两个类的样例，训练时间短
OvR：训练N个分类器，存储开销和测试时间小，训练用到全部训练样例，训练时间长
预测性能取决于具体数据分布，多数情况下两者差不多
##### 纠错输出码：多对多
海明距离，对两个位串进行异或运算，计算出异或运算结果中1的个数
ECOC编码对分类器错误有一定的容忍和修正能力，编码越长、纠错能力越强
对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠错能力越强。
##### 类别不平衡
常见的类别不平衡学习方法：过采样、欠采样、阈值移动
${y \over {1-y}}>{m^+ \over {m^-}}$则预测为正例
基本策略为“再缩放”$$ \frac{y'}{1 - y'} = \frac{y}{1 - y} \cdot \frac{m^{-}}{m^{+}} $$
但精确估计${m^+ \over {m^-}}$很难

---
#### 决策树
CLS（第一个决策树算法）——ID3（使决策树算法受到关注）——C4.5（广泛使用的 ）——CART（能够应用于回归问题的）——RF
三种停止条件：
	当该节点中样本属于同一类，不必再划分
	当该节点中包含的样本集合为空，无法再划分
	当前属性集为空，或是所有样本在所有属性上的取值相同，无法划分
		<img src="Pasted image 20250628211044.png" width=500>
1. 信息增益：$Gain(D, a)=Ent(D)-\Sigma_{v=1}^V\frac{|D^v|}{|D|}Ent(D^v)$信息增益最大的选为划分属性——ID3
	可能对取值数目较多的属性有偏好，当将“编号”作为一个属性时出现偏好“编号”
2. 增益率：$Gain\_ratio(D,a)= {Gain(D,a)\over {IV(a)}}$  $IV(a)=-\Sigma_{v=1}^V \frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}$
	启发式：先从候选划分属性中找出信息增益高于平均水平的，再从中选取增益率最高的
	对取值数目较少的属性有偏好——C4.5
3. 基尼指数 $Gini(D) = \sum_{k=1}^{|\mathcal{y}|} \sum_{\substack{k' \neq k}} p_k p_{k'}=\Sigma_{k=1}^{|y|}1-p_k^2$
	反映了从D中随机抽取两个样例，其类别标记不一致的概率
	Gini（D）越小，数据集D的纯度越高，在候选属性集合中，选取那个使划分后基尼指数最小的属性
	属性a的基尼指数：$Gini\_index(D,a)=\Sigma_{v=1}^V\frac{|D^v|}{|D|}Gini(D^v)$
划分选择的各种准则虽然对决策树的尺寸有较大影响，但对泛化性能的影响很有限
剪枝方法和程度对决策树泛化性能的影响更为显著
- 预剪枝：训练时间开销降低，测试时间开销降低，过拟合风险降低，欠拟合风险增加
- 后剪枝：训练时间开销增加，测试时间开销降低，过拟合风险降低，欠拟合风险基本不变
- 泛化性能：后剪枝通常优于预剪枝
连续值：连续属性离散化
	二分法：n个属性值可以形成n-1个候选划分，可将它们当作n-1个离散属性值处理
属性值缺失：
	仅使用无缺失的样例，对数据的极大浪费
	样本赋权、权重划分
单变量决策树：每个非叶节点仅考虑一个划分属性，产生“轴平行”分类面
多变量决策树：每个结点不仅考虑一个属性，甚至可以在结点嵌入神经网络或其他非线性模型

---
#### 集成学习
集成个体应当：好而不同——核心问题；事实上，个体学习器的准确性和多样性是存在冲突的。

在一定条件下，随着集成分类器数目的增加，集成的错误率将指数级下降，最终趋向于0。
关键假设：基学习器的误差相互独立。——现实任务中，个体学习器是为解决同一个问题训练出来的，显然不可能相互独立。

集成学习大致分为两类：
boosting：个体学习器之间存在强依赖关系，必须串行生成的序列化方法。
	先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器，如此重复进行，直至基学习器数目达到预先设定的值T，最终将这T个基学习器进行加权结合。
代表算法：AdaBoost
	1. 基学习器的线性组合$H(x)=\Sigma\alpha_th_t$ $\alpha_t=\frac{1}{2}ln\frac{1-\epsilon_t}{\epsilon_t}$
	2. 指数损失函数$l_{exp}$
	3. 损失函数对$H(x)$求偏导，令其为零，得到$H(x)$
	4. 进一步计算$sign(H(x))$，发现其值与后验概率较大者所属类别相同，符合贝叶斯最小错误率，说明指数损失函数是分类任务原来0/1损失函数的一致的替代函数。
	数据分布的学习：重赋权法、重采样法
	重启动，避免训练过程过早停止
	从偏差-方差的角度：降低**偏差**，可基于泛化性能相当弱的学习器构造出很强的集成
Bagging与随机森林：个体学习器之间不存在强依赖关系，可同时并行生成的序列化方法。
代表算法：
1. Bagging：
	时间复杂度低：假定基学习器的计算复杂度为O(m)，采样与投票/平均过程的复杂度为O(s)，则Bagging的复杂度大致为T(O(m)+O(s))，其中O(s)很小且T是个不大的常数，因此训练一个bagging集成与直接使用基学习器的复杂度同阶。
	可使用包外估计
	从偏差-方差的角度：降低**方差**，在不剪枝的决策树、神经网络等易受样本影响的学习器上效果更好
2. 随机森林：是bagging的一个扩展变种
    采样的随机性
    属性选择的随机性
	
结合策略：
学习器的组合可以从三个方面带来好处：统计、计算、表示
平均法：
	简单平均法:
	$$H(x)=\frac{1}{T}\Sigma_{i=1}^Th_i(x)$$
	加权平均法：
	$$H(x)=\Sigma_{i=1}^Tw_ih_i(x), \text{ }w_i\ge0\text{ }and\text{ }\Sigma_{i=1}^Tw_i=1$$
	简单平均法是加权平均法的特例，集成学习中的各种结合方法都可以看成是加权平均法的变种或特例，加权平均法可以认为是集成学习研究的基本出发点。加权平均法未必优于简单平均法。
投票法：
	绝对多数投票法$$H(x)=\begin{cases}c_j, & \text{if }\Sigma_{i=1}^Th_i^j(x)>{1\over 2}\Sigma_{k=1}^l\Sigma_{i=1}^Th_i^k(x) \\
	\text{rejection}, & \text{otherwise}\end{cases}$$
	相对多数投票法$$H(x)=c_{arg_{j}max\Sigma_{i=1}^Th_i^j(x)}$$
	加权投票法$$H(x)=c_{arg_{j}max\Sigma_{i=1}^Tw_ih_i^j(x)}$$
学习法
	Stacking
	多响应线性回归（MLR）作为次级学习器的学习算法，效果较好
	贝叶斯模型平均（BMA）

多样性：
误差-分歧分解
	分歧项代表了个体学习器在样本x上的不一致性，即在一定程度上反映了个体学习器的多样性，个体学习器$h_i$和集成H的平方误差分别为$$E(h_i|x)=(f(x)-h_i(x))^2$$$$E(H|x)=(f(x)-H(x))^2$$
	
	$\overline{E}=\Sigma_{i=1}^Tw_iE_i$
	$\overline{A}=\Sigma_{i=1}^Tw_iA_i$
	$E=\overline{E}-\overline{A}$
	个体学习器精确性越高、多样性越大，则集成效果越好。称为误差-分歧分解
	为什么不能直接把$\overline{E}-\overline{A}$作为优化目标来求解？
		他们定义在整个样本空间上，$\overline{A}$不是一个可直接操作的多样性度量，仅在集成构造好后才能估计，上面的推导过程只适用于回归学习，难以直接推广到分类学习任务上去
多样性度量：
	用于度量集成中个体学习器的多样性
	对于二分类问题，分类器$h_i$与$h_j$的预测结果联立表![[Pasted image 20250625152637.png]]
	不合度量：
	$$dis_{ij}={{b+c}\over m}$$
	相关系数：
	$$\rho_{ij}={{ad-bc}\over\sqrt{(a+b)(a+c)(c+d)(b+d)}}$$
	Q-统计量
	$$Q_{ij}={{ad-bc}\over{ad+bc}}$$
	$|Q_{ij}|\le|\rho_{ij}|$
	K-统计量——通常为非负值，1完全一致、0偶然一致
	$$k={{p_1-p_2}\over{1-p_2}}$$
		$p_1={{a+d}\over m}$
		$p_2={{(a+b)(a+c)+(c+d)(b+d)}\over m^2}$ 
	k-误差图——横坐标对应这对分类器的k值，纵坐标表示他们的平均误差
**多样性扰动**
	常见的增强个体学习器的多样性的方法
    数据样本扰动：通常基于采样法
	    Bagging中的自助采样法
	    AdaBoost中的序列采样
	    对数据样本扰动敏感的基学习器（不稳定基学习器）：决策树、神经网络等，数据样本扰动对“不稳定基学习器”很有效
	    对数据样本扰动不敏感的基学习器（稳定基学习器）：线性学习器、支持向量机、朴素贝叶斯、k近邻等
    输入属性扰动：
	    随机子空间算法
    输出表示扰动：
	    翻转法
	    输出调剂法
	    ECOC法
    算法参数扰动
	    负相关法
	    不同的多样性增强机制同时使用

---
#### SVM
将训练样本分开的超平面可能有很多，应选择“正中间”的，容忍性好、鲁棒性好、泛化能力最强
核心设计思想：最大化间隔，超平面距离训练样本都比较远；寻找w和b，使$\gamma$最大
采用拉格朗日乘子法求解线性规划问题：如果有m个不等式约束，需要讨论$2^m$种情况。
采用对偶方法，通过求解对偶问题，可以得到原始问题的最优解的一个下界，这有助于理解原始问题的特性。
问题转化为
<img src="Pasted image 20250626143904.png" width=300>
支持向量机解的稀疏性：模型训练完成后，大部分的训练样本都不需保留，最终模型仅与支持向量有关。
KKT条件
<img src="Pasted image 20250626152911.png" width=200>
从而确定：$$\begin{aligned}a_i=0、y_if(x_i)\ge1 \\ a_i>0、y_if(x_i) = 1 \end{aligned}$$
其中$a_i>0$对应的向量是支持向量

**高效求解方法——SMO**
基本思路：不断执行如下两个步骤直至收敛
第一步：选取一对需更新的变量$\alpha_i$和$\alpha_j$
第二步：固定$\alpha_i$和$\alpha_j$以外的参数，求解对偶问题更新$\alpha_i$和$\alpha_j$
仅考虑$\alpha_i$和$\alpha_j$时，对偶问题的约束变为
$$\alpha_iy_i+\alpha_jy_j=-\Sigma_{k \not= i,j }a_ky_k  ,{\alpha_i \ge0, \alpha_j \ge 0}$$
用一个变量表示另一个变量，回代入对偶问题可得到一个单变量的二次规划，该问题具有闭式解

偏移项b：由支持向量决定。
第一个变量是在KKT条件不满足的中间选择，直观来看，KKT条件违背的程度越大，则变量更新后可能会使得目标函数的增幅越大，从而选择违背KKT条件程度越大的变量
第二个变量应选择使得目标函数增长最快的变量，常用**启发式**，也就是两样本的间距最大

核函数
若不存在一个能正确划分两类样本的超平面，将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。
设样本x映射后的向量为$\phi(x)$，划分超平面为$f(x)=w^T\phi(x)+b$
基本想法：不显式地设计核映射，而是设计核函数$k(x_i,x_j)=\phi(x_i)^T\phi(x_j)$
Mercer定理（充分非必要）：只要一个对称函数所对应地核矩阵半正定，则它就能作为核函数来使用。
<img src="Pasted image 20250626154521.png", width=500>
对称的核函数$k(x,y)=k(y,x)$，对应的核矩阵也是对称的
如果核函数是正定的，则核矩阵K是半正定的（所有特征值非负）
线性核函数：$k(x,y)=x^Ty$   核矩阵K的元素$K_{ij}=x_i^Tx_j$，显然K是对称的
高斯核函数（RBF核）：$k(x,y)=exp(-{||x-y||\over{2\sigma^2}})$，也是对称的

核函数选择成为SVM的最大变数
经验：文本数据使用线性核，情况不明使用高斯核
核函数的性质：
1. 核函数的线性组合仍为核函数
2. 和函数的直积仍为核函数
3. 设$k(x_1,x_2)$为核函数，则对于任意函数g，$g(x_1)k(x_1,x_2)g(x_2)$仍为核函数
![[Pasted image 20250701132058.png]]

---
#### 神经网络
神经网络学得的知识蕴含在连接权重和阈值中
多层前馈神经网络有强大的表示能力：只需一个包含足够多神经元的隐层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数；如何确定隐层神经元数是未决问题，实际常用“试错法”
**BP（误差逆传播算法）**
	预处理：属性值一般伸缩到[-1,1]，Y伸缩到[0,1]
	**标准BP算法**：每次针对单个训练样例更新权值和阈值、参数更新频繁，不同样例可能抵消，需要多次迭代
	**累积BP算法**：优化目标是最小化整个训练集上的累计误差，读取整个训练集一遍才对参数进行更新，参数更新频率较低
	在很多任务中，累计误差下降到一定程度后，进一步下降会非常缓慢，这时标准BP算法往往会获得较好的解，尤其当训练集非常大时效果更明显

###### 缓解过拟合：
早停
	若训练误差连续a轮的变化小于b，则停止训练
	使用验证集：若训练误差降低，验证误差升高，则停止训练
正则化
	在误差目标函数中增加一项描述网络复杂度
###### 跳出局部极小的常见策略：
	模拟退火：在每一步都以一定的概率接受比当前解更差的结果，从而有助于“跳出”局部极小，在每步迭代过程中，接受次优解的概率要随着时间的推移而逐渐降低，从而保证算法稳定。
	随机梯度下降：在计算时加入了随机因素，即便陷入局部极小点，计算出的梯度仍可能不为0，有机会跳出局部极小继续搜索。
	遗传算法
	不同的初始参数
	随机扰动

提升模型复杂度——提升模型学习能力
1. 增加隐层神经元个数（模型宽度）
2. 增加隐层数目（模型深度）
增加隐层数目比增加隐层神经元个数更有效：
	1. 增加了拥有激活函数的神经元个数
	2. 增加了激活函数嵌套的层数
增加了过拟合风险，增加了训练难度
误差梯度在多隐层内传播时，往往会发散而不能收敛到稳定状态，因此，难以直接用经典BP算法训练
深度学习最重要的特征：表示学习、联合优化

---
#### CNN
特点：
	稀疏连接
	权值共享：等变性
	池化：不变性
局部连接：感受野逐层扩大
权值共享：
	等变性$f(g(x))=g(f(x))$
	先平移再卷积=先卷积再平移
池化：减少表征大小
	最大池化
	均值池化
	对平移等变换操作具有近似不变性
	不变性$f(x)=f(g(x))$
	
浅层学到的特征为简单的边缘、角点、纹理、几何形状、表面等
深层学到的特征则更为复杂抽象，为狗、人脸、键盘等等
经典的CNN：
	LeNet-5
	AlexNet：第一个现代深度卷积网络模型
	ResNet：

---
#### RNN
擅长处理的数据类型：序列化数据：文本、音频、时间序列、代码
每一时刻的隐藏层不仅由该时刻的输入层决定，还有上一时刻的隐藏层决定

##### LSTM 长短期记忆神经网络
遗忘门
	![[Pasted image 20250626214850.png]]
	![[Pasted image 20250626220016.png]]
描述当前输入的单元状态$\mathbf{\tilde{c}}_t$，它是根据上一次的输出和本次输入来计算的：
	![[Pasted image 20250626220110.png]]
计算当前时刻的单元状态$\mathbf{c}_t$。它是由上一次的单元状态$\mathbf{c}_{t-1}$按元素乘以遗忘门$f_t$，再用当前输入的单元状态$\mathbf{\tilde{c}}_t$按元素乘以输入门$i_t$，再将两个积加和产生的：
	![[Pasted image 20250626220207.png]]
由于遗忘门的控制，它可以保存很久很久之前的信息，由于输入门的控制，它又可以避免当前无关紧要的内容进入记忆。
	![[Pasted image 20250626220415.png]]
LSTM最终的输出，是由输出门和单元状态共同确定的：
	![[Pasted image 20250626220432.png]]

![[Pasted image 20250626214634.png]]

<img src="Pasted image 20250626220804.png" width=500>
##### GRU
![[Pasted image 20250626221248.png]]
![[Pasted image 20250629103937.png]]
重置门：Zt
更新门：rt
##### RNN VS LSTM VS GRU
RNN：出现梯度消失、梯度爆炸的问题
共性：
通过引入门控机制，在一定程度上解决梯度爆炸、梯度消失问题
区别：
GRU将输入门、遗忘门、输出门变为两个门：更新门、重置门
LSTM使用输入门、遗忘门分别独立控制新、老记忆更替，GRU中由一个门（更新门）控制新老记忆更替

RNN的变体：LSTM、GRU、双向RNN、Seq2Seq

固定窗口的神经语言模型：
	n-gram
	现存问题：
		固定窗口过小；增大窗口就要增加W；窗口不能足够大
		输入向量乘的权重矩阵不同，输入处理并不相同
基于RNN的语言模型：
	可以处理任意长度的输入
	t时刻的计算可以使用来自之前的信息
	对于更长的输入文本，模型的体量并没有增加
	每个时间步施加相同的权重，对于输入的处理是相似的
	缺点：
		循环计算很慢
		很难获取来自许多步之前的信息
	任务：
		序列标注、文本分类、作为编码器

---
#### Transformer
Vison：ViT
Robotics：RT-1
大模型预训练
解决RNN缺陷：
	难以抓取远距离关系、难以并行
优势：可以并行计算、有更优秀的长距离关系处理能力、多头注意力机制可以学习不同种类的关系

Transformer结构：
	编码器、解码器
	编码器、解码器层
	注意力机制：
		自注意力机制：
			1. 计算Q、K、V
			2. 计算Score、除以$\sqrt{d_k}$
			3. Softmax得到权重
			4. 权重乘以v得到z
		多头注意力机制：
			不同的头关注位置可能不同
			构筑不同的表征子空间
	前馈层：将多头注意力得到的z拼接与权重矩阵$W^o$相乘得到Z矩阵
	编码器层
	位置编码
	解码：K、V来自编码器，Q来自先前输出的单词
残差连接
	防止过拟合、防止梯度消失
层归一化
	对每个句子的representation做归一化
	稳定梯度

---
#### 模型对比
CNN适用于图像识别
RNN擅长处理序列数据
Transformer擅长处理长序列数据：文本、时间序列、音频、代码

---
#### 提示工程
提示：Prompts 通过向语言模型传递指令与上下文信息以实现目标任务的交互单元
	指令：instructions
	上下文：context
	输入数据：input data
	输出暗示：output indicator
对研究、发现和技术进步有重要意义
有助于测试和评估大型语言模型的能力边界
支持构建各种基于LLM的创新应用
###### 提示工程技巧
1. 设置不同的参数：top_n、temperature：需要精确答案，保持在较低值，多样化响应，保持在较高值
2. 为不同任务设计不同的提示词
3. 少样本提示：通过示例引导模型给出更好回答
4. 思维链提示：指示模型在响应时对任务进行推理，进一步提升提示的效果，对于**需要推理的任务**尤其有效
	1. 零样本思维链：Let's think step by step加入原始提示开头
	2. 少样本思维链
5. 自我一致性提示：旨在改进思维链提示中使用的简单贪婪解码方法
	通过少样本思维链生成多条多样化推理路径，然后选择一致性最好的答案
	**算术、常识推理任务**
6. 知识生成提示：将额外知识作为上下文，提升模型在常识推理等复杂任务中的表现
	知识生成：由语言模型自动产生相关知识陈述
	提示增强：将生成的知识作为附加上下文整合到提示中
	预测选择：采用置信度最高的预测结果作为最终输出
7. ReAct：核心机制是让大型语言模型交替生成推理轨迹与任务相关操作步骤
8. 程序辅助语言模型（PAL）LLM在读取问题后生成程序代码作为中间推理过程步骤
应用：
	将LLM与外部工具或API结合使用
	基于外部数据增强的文本生成

---
#### 聚类
将数据集中的样本划分为若干个通常不相交的子集，聚类既可以作为一个单独过程，用于寻找数据内在的分布结构，也可以作为分类等其他学习任务的前驱过程

性能度量
簇内相似度高
簇间相似度低

外部指标：
将聚类结果与某个“参考模型”进行比较
a=|SS| $|SS|=\{(x_i,x_j)|\lambda_i=\lambda_j,\lambda_i^*=\lambda_j^*,i<j\}$
b=|SD| $|SD|=\{(x_i,x_j)|\lambda_i=\lambda_j,\lambda_i^* \not=\lambda_j^*,i<j\}$
c=|DS| $|DS|=\{(x_i,x_j)|\lambda_i \not =\lambda_j,\lambda_i^*=\lambda_j^*,i<j\}$
d=|DD| $|DD|=\{(x_i,x_j)|\lambda_i\not=\lambda_j,\lambda_i^*\not=\lambda_j^*,i<j\}$
1. Jaccard       $JC=\frac{a}{a+b+c}$
2. FM指数       $FMI=\sqrt{\frac{a}{a+b}\frac{a}{a+c}}$
3. Rand指数        $RI=\frac{2(a+b)}{m(m-1)}$
上述指标均$\in[0,1]$，且越大越好

内部指标：
1. 直接考察聚类结果而不使用任何参考模型
2. 簇内样本间的平均距离——小
3. 簇内样本间的最远距离——小
4. 簇$C_i$和簇$C_j$最近样本间的距离——大
5. 簇$C_i$和簇$C_j$中心点之间的距离——大
6. DB指数——越小越好
7. Dunn指数——越大越好

属性
- 连续属性
- 离散属性
- 有序属性
- 无序属性
距离计算
闵可夫斯基距离$dist(x_i,x_j)=(\Sigma_{u=1}^n|X_{iu}-x_{ju}|^p)^{\frac{1}{p}}$
VDM处理无序属性
$MinkovDM_p$处理混合属性
加权距离：当样本中不同属性的重要性不同时

##### 原型聚类
基于原型的聚类，假设聚类结构可通过一组原型刻画
1. K-means
2. 学习向量量化算法（LVQ）
	- 假设数据样本带有类别标记，学习过程中利用样本的这些监督信息来辅助聚类
	- <img src="Pasted image 20250630215004.png" width=400>
3. 高斯混合聚类算法
	- 采用概率模型来表达聚类原型
##### 密度聚类
DBSCAN
- 由密度可达关系导出的最大密度相连样本集合
- 实际上，若x为核心对象，由x密度可达的所有样本组成的集合为X，则X为满足连接性与最大性的簇
- ![[Pasted image 20250630215409.png]]
##### 层次聚类
"自顶而下"“自底而上”
Agnes——“自底而上”
类间聚类度量
1. 最小距离
2. 最大距离
3. 平均距离
![[Pasted image 20250630215426.png]]
